{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import pandas as pd\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>...</th>\n",
       "      <th>1061</th>\n",
       "      <th>1062</th>\n",
       "      <th>1063</th>\n",
       "      <th>1064</th>\n",
       "      <th>1065</th>\n",
       "      <th>1066</th>\n",
       "      <th>1067</th>\n",
       "      <th>1068</th>\n",
       "      <th>1069</th>\n",
       "      <th>1070</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HB-52</td>\n",
       "      <td>1.499853</td>\n",
       "      <td>1.500665</td>\n",
       "      <td>1.501564</td>\n",
       "      <td>1.502536</td>\n",
       "      <td>1.503537</td>\n",
       "      <td>1.504548</td>\n",
       "      <td>1.505588</td>\n",
       "      <td>1.506689</td>\n",
       "      <td>1.507828</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636411</td>\n",
       "      <td>1.637350</td>\n",
       "      <td>1.636452</td>\n",
       "      <td>1.634370</td>\n",
       "      <td>1.632287</td>\n",
       "      <td>1.630265</td>\n",
       "      <td>1.630722</td>\n",
       "      <td>1.633166</td>\n",
       "      <td>1.636204</td>\n",
       "      <td>1.637872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HB-52</td>\n",
       "      <td>1.530877</td>\n",
       "      <td>1.531669</td>\n",
       "      <td>1.532524</td>\n",
       "      <td>1.533419</td>\n",
       "      <td>1.534308</td>\n",
       "      <td>1.535169</td>\n",
       "      <td>1.536024</td>\n",
       "      <td>1.536916</td>\n",
       "      <td>1.537830</td>\n",
       "      <td>...</td>\n",
       "      <td>1.643299</td>\n",
       "      <td>1.644222</td>\n",
       "      <td>1.643302</td>\n",
       "      <td>1.641195</td>\n",
       "      <td>1.639088</td>\n",
       "      <td>1.637046</td>\n",
       "      <td>1.637493</td>\n",
       "      <td>1.639938</td>\n",
       "      <td>1.642981</td>\n",
       "      <td>1.644649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HB-52</td>\n",
       "      <td>1.607175</td>\n",
       "      <td>1.608642</td>\n",
       "      <td>1.610044</td>\n",
       "      <td>1.611357</td>\n",
       "      <td>1.612540</td>\n",
       "      <td>1.613585</td>\n",
       "      <td>1.614534</td>\n",
       "      <td>1.615456</td>\n",
       "      <td>1.616359</td>\n",
       "      <td>...</td>\n",
       "      <td>1.703343</td>\n",
       "      <td>1.704291</td>\n",
       "      <td>1.703329</td>\n",
       "      <td>1.701137</td>\n",
       "      <td>1.698946</td>\n",
       "      <td>1.696822</td>\n",
       "      <td>1.697278</td>\n",
       "      <td>1.699806</td>\n",
       "      <td>1.702953</td>\n",
       "      <td>1.704677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HB-52</td>\n",
       "      <td>1.677333</td>\n",
       "      <td>1.678098</td>\n",
       "      <td>1.678930</td>\n",
       "      <td>1.679809</td>\n",
       "      <td>1.680688</td>\n",
       "      <td>1.681539</td>\n",
       "      <td>1.682384</td>\n",
       "      <td>1.683260</td>\n",
       "      <td>1.684145</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755067</td>\n",
       "      <td>1.756013</td>\n",
       "      <td>1.754996</td>\n",
       "      <td>1.752716</td>\n",
       "      <td>1.750441</td>\n",
       "      <td>1.748238</td>\n",
       "      <td>1.748696</td>\n",
       "      <td>1.751290</td>\n",
       "      <td>1.754525</td>\n",
       "      <td>1.756294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HB-52</td>\n",
       "      <td>1.507830</td>\n",
       "      <td>1.509293</td>\n",
       "      <td>1.510683</td>\n",
       "      <td>1.511977</td>\n",
       "      <td>1.513145</td>\n",
       "      <td>1.514180</td>\n",
       "      <td>1.515125</td>\n",
       "      <td>1.516049</td>\n",
       "      <td>1.516964</td>\n",
       "      <td>...</td>\n",
       "      <td>1.641968</td>\n",
       "      <td>1.642877</td>\n",
       "      <td>1.641946</td>\n",
       "      <td>1.639829</td>\n",
       "      <td>1.637714</td>\n",
       "      <td>1.635664</td>\n",
       "      <td>1.636101</td>\n",
       "      <td>1.638535</td>\n",
       "      <td>1.641567</td>\n",
       "      <td>1.643227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 332 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Predictor       740       741       742       743       744       745  \\\n",
       "0     HB-52  1.499853  1.500665  1.501564  1.502536  1.503537  1.504548   \n",
       "1     HB-52  1.530877  1.531669  1.532524  1.533419  1.534308  1.535169   \n",
       "2     HB-52  1.607175  1.608642  1.610044  1.611357  1.612540  1.613585   \n",
       "3     HB-52  1.677333  1.678098  1.678930  1.679809  1.680688  1.681539   \n",
       "4     HB-52  1.507830  1.509293  1.510683  1.511977  1.513145  1.514180   \n",
       "\n",
       "        746       747       748    ...         1061      1062      1063  \\\n",
       "0  1.505588  1.506689  1.507828    ...     1.636411  1.637350  1.636452   \n",
       "1  1.536024  1.536916  1.537830    ...     1.643299  1.644222  1.643302   \n",
       "2  1.614534  1.615456  1.616359    ...     1.703343  1.704291  1.703329   \n",
       "3  1.682384  1.683260  1.684145    ...     1.755067  1.756013  1.754996   \n",
       "4  1.515125  1.516049  1.516964    ...     1.641968  1.642877  1.641946   \n",
       "\n",
       "       1064      1065      1066      1067      1068      1069      1070  \n",
       "0  1.634370  1.632287  1.630265  1.630722  1.633166  1.636204  1.637872  \n",
       "1  1.641195  1.639088  1.637046  1.637493  1.639938  1.642981  1.644649  \n",
       "2  1.701137  1.698946  1.696822  1.697278  1.699806  1.702953  1.704677  \n",
       "3  1.752716  1.750441  1.748238  1.748696  1.751290  1.754525  1.756294  \n",
       "4  1.639829  1.637714  1.635664  1.636101  1.638535  1.641567  1.643227  \n",
       "\n",
       "[5 rows x 332 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading the csv file and putting it into 'df' object.\n",
    "df = pd.read_csv(\"M:\\Imarticus\\python project\\crop-varietal-identification-with-scio\\Barley.data.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>...</th>\n",
       "      <th>1061</th>\n",
       "      <th>1062</th>\n",
       "      <th>1063</th>\n",
       "      <th>1064</th>\n",
       "      <th>1065</th>\n",
       "      <th>1066</th>\n",
       "      <th>1067</th>\n",
       "      <th>1068</th>\n",
       "      <th>1069</th>\n",
       "      <th>1070</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.499853</td>\n",
       "      <td>1.500665</td>\n",
       "      <td>1.501564</td>\n",
       "      <td>1.502536</td>\n",
       "      <td>1.503537</td>\n",
       "      <td>1.504548</td>\n",
       "      <td>1.505588</td>\n",
       "      <td>1.506689</td>\n",
       "      <td>1.507828</td>\n",
       "      <td>1.508937</td>\n",
       "      <td>...</td>\n",
       "      <td>1.636411</td>\n",
       "      <td>1.637350</td>\n",
       "      <td>1.636452</td>\n",
       "      <td>1.634370</td>\n",
       "      <td>1.632287</td>\n",
       "      <td>1.630265</td>\n",
       "      <td>1.630722</td>\n",
       "      <td>1.633166</td>\n",
       "      <td>1.636204</td>\n",
       "      <td>1.637872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.530877</td>\n",
       "      <td>1.531669</td>\n",
       "      <td>1.532524</td>\n",
       "      <td>1.533419</td>\n",
       "      <td>1.534308</td>\n",
       "      <td>1.535169</td>\n",
       "      <td>1.536024</td>\n",
       "      <td>1.536916</td>\n",
       "      <td>1.537830</td>\n",
       "      <td>1.538712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.643299</td>\n",
       "      <td>1.644222</td>\n",
       "      <td>1.643302</td>\n",
       "      <td>1.641195</td>\n",
       "      <td>1.639088</td>\n",
       "      <td>1.637046</td>\n",
       "      <td>1.637493</td>\n",
       "      <td>1.639938</td>\n",
       "      <td>1.642981</td>\n",
       "      <td>1.644649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.607175</td>\n",
       "      <td>1.608642</td>\n",
       "      <td>1.610044</td>\n",
       "      <td>1.611357</td>\n",
       "      <td>1.612540</td>\n",
       "      <td>1.613585</td>\n",
       "      <td>1.614534</td>\n",
       "      <td>1.615456</td>\n",
       "      <td>1.616359</td>\n",
       "      <td>1.617205</td>\n",
       "      <td>...</td>\n",
       "      <td>1.703343</td>\n",
       "      <td>1.704291</td>\n",
       "      <td>1.703329</td>\n",
       "      <td>1.701137</td>\n",
       "      <td>1.698946</td>\n",
       "      <td>1.696822</td>\n",
       "      <td>1.697278</td>\n",
       "      <td>1.699806</td>\n",
       "      <td>1.702953</td>\n",
       "      <td>1.704677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.677333</td>\n",
       "      <td>1.678098</td>\n",
       "      <td>1.678930</td>\n",
       "      <td>1.679809</td>\n",
       "      <td>1.680688</td>\n",
       "      <td>1.681539</td>\n",
       "      <td>1.682384</td>\n",
       "      <td>1.683260</td>\n",
       "      <td>1.684145</td>\n",
       "      <td>1.684969</td>\n",
       "      <td>...</td>\n",
       "      <td>1.755067</td>\n",
       "      <td>1.756013</td>\n",
       "      <td>1.754996</td>\n",
       "      <td>1.752716</td>\n",
       "      <td>1.750441</td>\n",
       "      <td>1.748238</td>\n",
       "      <td>1.748696</td>\n",
       "      <td>1.751290</td>\n",
       "      <td>1.754525</td>\n",
       "      <td>1.756294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.507830</td>\n",
       "      <td>1.509293</td>\n",
       "      <td>1.510683</td>\n",
       "      <td>1.511977</td>\n",
       "      <td>1.513145</td>\n",
       "      <td>1.514180</td>\n",
       "      <td>1.515125</td>\n",
       "      <td>1.516049</td>\n",
       "      <td>1.516964</td>\n",
       "      <td>1.517836</td>\n",
       "      <td>...</td>\n",
       "      <td>1.641968</td>\n",
       "      <td>1.642877</td>\n",
       "      <td>1.641946</td>\n",
       "      <td>1.639829</td>\n",
       "      <td>1.637714</td>\n",
       "      <td>1.635664</td>\n",
       "      <td>1.636101</td>\n",
       "      <td>1.638535</td>\n",
       "      <td>1.641567</td>\n",
       "      <td>1.643227</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        740       741       742       743       744       745       746  \\\n",
       "0  1.499853  1.500665  1.501564  1.502536  1.503537  1.504548  1.505588   \n",
       "1  1.530877  1.531669  1.532524  1.533419  1.534308  1.535169  1.536024   \n",
       "2  1.607175  1.608642  1.610044  1.611357  1.612540  1.613585  1.614534   \n",
       "3  1.677333  1.678098  1.678930  1.679809  1.680688  1.681539  1.682384   \n",
       "4  1.507830  1.509293  1.510683  1.511977  1.513145  1.514180  1.515125   \n",
       "\n",
       "        747       748       749    ...         1061      1062      1063  \\\n",
       "0  1.506689  1.507828  1.508937    ...     1.636411  1.637350  1.636452   \n",
       "1  1.536916  1.537830  1.538712    ...     1.643299  1.644222  1.643302   \n",
       "2  1.615456  1.616359  1.617205    ...     1.703343  1.704291  1.703329   \n",
       "3  1.683260  1.684145  1.684969    ...     1.755067  1.756013  1.754996   \n",
       "4  1.516049  1.516964  1.517836    ...     1.641968  1.642877  1.641946   \n",
       "\n",
       "       1064      1065      1066      1067      1068      1069      1070  \n",
       "0  1.634370  1.632287  1.630265  1.630722  1.633166  1.636204  1.637872  \n",
       "1  1.641195  1.639088  1.637046  1.637493  1.639938  1.642981  1.644649  \n",
       "2  1.701137  1.698946  1.696822  1.697278  1.699806  1.702953  1.704677  \n",
       "3  1.752716  1.750441  1.748238  1.748696  1.751290  1.754525  1.756294  \n",
       "4  1.639829  1.637714  1.635664  1.636101  1.638535  1.641567  1.643227  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collecting indepedent variables in X\n",
    "X = df.iloc[:,1:332]\n",
    "X_col = X.columns\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#collecting depedent variable in Y\n",
    "Y=df['Predictor']\n",
    "Y=pd.DataFrame(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predictor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Predictor\n",
       "0         21\n",
       "1         21\n",
       "2         21\n",
       "3         21\n",
       "4         21"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import preprocessing\n",
    "le = preprocessing.LabelEncoder()\n",
    "Y_encoded = Y.apply(le.fit_transform)\n",
    "Y_encoded.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-processing methods are helpful in eliminating noise generated by spectral data. Raw spectral data were thus processed using a combination of scatter corrections that include Standard Normal Variate (SNV) as well as first and second degree derivatives. The Savitzky-Golay and Gap-segment derivative smoothing filtering algorithms also usefull in eliminating noise.\n",
    "\n",
    "Here I am using Savitzky-Golay filter with second degree derivative."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Savitzky-Golay filter with second degree derivative.\n",
    "from scipy.signal import savgol_filter \n",
    "\n",
    "sg=savgol_filter(X,window_length=11, polyorder=3, deriv=2, delta=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>740</th>\n",
       "      <th>741</th>\n",
       "      <th>742</th>\n",
       "      <th>743</th>\n",
       "      <th>744</th>\n",
       "      <th>745</th>\n",
       "      <th>746</th>\n",
       "      <th>747</th>\n",
       "      <th>748</th>\n",
       "      <th>749</th>\n",
       "      <th>...</th>\n",
       "      <th>1061</th>\n",
       "      <th>1062</th>\n",
       "      <th>1063</th>\n",
       "      <th>1064</th>\n",
       "      <th>1065</th>\n",
       "      <th>1066</th>\n",
       "      <th>1067</th>\n",
       "      <th>1068</th>\n",
       "      <th>1069</th>\n",
       "      <th>1070</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000084</td>\n",
       "      <td>0.000073</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000030</td>\n",
       "      <td>-0.000044</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000319</td>\n",
       "      <td>0.000781</td>\n",
       "      <td>0.001243</td>\n",
       "      <td>0.001705</td>\n",
       "      <td>0.002167</td>\n",
       "      <td>0.002629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>-0.000024</td>\n",
       "      <td>-0.000036</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000474</td>\n",
       "      <td>-0.000300</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001250</td>\n",
       "      <td>0.001714</td>\n",
       "      <td>0.002178</td>\n",
       "      <td>0.002642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.000139</td>\n",
       "      <td>-0.000128</td>\n",
       "      <td>-0.000117</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000094</td>\n",
       "      <td>-0.000082</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000060</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000462</td>\n",
       "      <td>-0.000491</td>\n",
       "      <td>-0.000310</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000334</td>\n",
       "      <td>0.000815</td>\n",
       "      <td>0.001296</td>\n",
       "      <td>0.001777</td>\n",
       "      <td>0.002258</td>\n",
       "      <td>0.002738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000055</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000022</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>-0.000061</td>\n",
       "      <td>-0.000071</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000471</td>\n",
       "      <td>-0.000502</td>\n",
       "      <td>-0.000315</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000347</td>\n",
       "      <td>0.000842</td>\n",
       "      <td>0.001337</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.002327</td>\n",
       "      <td>0.002822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.000148</td>\n",
       "      <td>-0.000133</td>\n",
       "      <td>-0.000119</td>\n",
       "      <td>-0.000105</td>\n",
       "      <td>-0.000091</td>\n",
       "      <td>-0.000077</td>\n",
       "      <td>-0.000069</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>-0.000055</td>\n",
       "      <td>-0.000045</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000446</td>\n",
       "      <td>-0.000473</td>\n",
       "      <td>-0.000299</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000322</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>0.001249</td>\n",
       "      <td>0.001713</td>\n",
       "      <td>0.002176</td>\n",
       "      <td>0.002640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 331 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        740       741       742       743       744       745       746  \\\n",
       "0  0.000084  0.000073  0.000061  0.000050  0.000039  0.000028  0.000010   \n",
       "1  0.000033  0.000027  0.000021  0.000014  0.000008  0.000001 -0.000011   \n",
       "2 -0.000139 -0.000128 -0.000117 -0.000105 -0.000094 -0.000082 -0.000078   \n",
       "3  0.000055  0.000043  0.000031  0.000020  0.000008 -0.000004 -0.000022   \n",
       "4 -0.000148 -0.000133 -0.000119 -0.000105 -0.000091 -0.000077 -0.000069   \n",
       "\n",
       "        747       748       749    ...         1061      1062      1063  \\\n",
       "0 -0.000011 -0.000030 -0.000044    ...    -0.000446 -0.000474 -0.000300   \n",
       "1 -0.000024 -0.000036 -0.000042    ...    -0.000446 -0.000474 -0.000300   \n",
       "2 -0.000073 -0.000069 -0.000060    ...    -0.000462 -0.000491 -0.000310   \n",
       "3 -0.000043 -0.000061 -0.000071    ...    -0.000471 -0.000502 -0.000315   \n",
       "4 -0.000062 -0.000055 -0.000045    ...    -0.000446 -0.000473 -0.000299   \n",
       "\n",
       "       1064      1065      1066      1067      1068      1069      1070  \n",
       "0  0.000008  0.000319  0.000781  0.001243  0.001705  0.002167  0.002629  \n",
       "1  0.000010  0.000322  0.000786  0.001250  0.001714  0.002178  0.002642  \n",
       "2  0.000010  0.000334  0.000815  0.001296  0.001777  0.002258  0.002738  \n",
       "3  0.000014  0.000347  0.000842  0.001337  0.001832  0.002327  0.002822  \n",
       "4  0.000010  0.000322  0.000786  0.001249  0.001713  0.002176  0.002640  \n",
       "\n",
       "[5 rows x 331 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sg_x=pd.DataFrame(sg, columns=X_col)\n",
    "\n",
    "sg_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the data into train and test\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test =train_test_split(sg_x, Y_encoded ,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=123,stratify=Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(random_state=52)\n",
    "Rf_fit=Rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.8083\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        10\n",
      "           1       0.53      0.90      0.67        10\n",
      "           2       1.00      1.00      1.00        10\n",
      "           3       0.91      1.00      0.95        10\n",
      "           4       0.70      0.70      0.70        10\n",
      "           5       1.00      1.00      1.00        10\n",
      "           6       1.00      0.80      0.89        10\n",
      "           7       0.80      0.80      0.80        10\n",
      "           8       0.75      0.90      0.82        10\n",
      "           9       0.67      0.60      0.63        10\n",
      "          10       0.75      0.90      0.82        10\n",
      "          11       0.62      0.50      0.56        10\n",
      "          12       1.00      0.90      0.95        10\n",
      "          13       1.00      1.00      1.00        10\n",
      "          14       0.80      0.80      0.80        10\n",
      "          15       0.62      0.50      0.56        10\n",
      "          16       1.00      1.00      1.00        10\n",
      "          17       0.78      0.70      0.74        10\n",
      "          18       0.50      0.40      0.44        10\n",
      "          19       1.00      1.00      1.00        10\n",
      "          20       0.91      1.00      0.95        10\n",
      "          21       0.75      0.90      0.82        10\n",
      "          22       0.75      0.60      0.67        10\n",
      "          23       0.78      0.70      0.74        10\n",
      "\n",
      "   micro avg       0.81      0.81      0.81       240\n",
      "   macro avg       0.81      0.81      0.81       240\n",
      "weighted avg       0.81      0.81      0.81       240\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  9  0  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  7  0  0  0  3  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  4  0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  1  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  1  2  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  5  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  2]\n",
      " [ 0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  3  0  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  9  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  0  0  0  1  0  6  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "print(\"Test Result:\\n\")        \n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test, y_pred)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test,y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 selected Features:\n",
      "['756' '790' '842' '854' '954' '982' '983' '1002' '1059' '1064']\n"
     ]
    }
   ],
   "source": [
    "#Reduction of variables using Recursive Feature Elimination(RFE) techineque\n",
    "\n",
    "from sklearn.feature_selection import RFE\n",
    "\n",
    "# RFE with 10 features\n",
    "\n",
    "rfe_10 = RFE(Rf,10)\n",
    "\n",
    "rfe_10.fit(X_train, y_train)\n",
    "\n",
    "# selected features\n",
    "features_bool = np.array(rfe_10.support_)\n",
    "features = np.array(X_col)\n",
    "result = features[features_bool]\n",
    "print('10 selected Features:')\n",
    "print(result)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7250\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  8  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  7  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  9  0  0  0  0  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  2  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  1  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  8  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  5  0  0  0  0  0  1  0  0  0  0  3  0]\n",
      " [ 0  0  0  0  2  0  1  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  2  0  0  0  0  0  0  0  0  0  0  6  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  2  0  0  0  2  0  0  0  0  5  0  0  1  0  0  0  0  0]\n",
      " [ 1  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  8  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  1  0  0  1  3  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  0  5  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  1  0  0  1  5  1]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  1  0  0  0  5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfe_10.predict(X_test)\n",
    "\n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15 selected Features:\n",
      "['756' '783' '789' '790' '842' '854' '858' '954' '982' '983' '1001' '1002'\n",
      " '1038' '1059' '1064']\n"
     ]
    }
   ],
   "source": [
    "# RFE with 15 features\n",
    "rfe_15 = RFE(Rf,15)\n",
    "\n",
    "# fit with 15 features\n",
    "rfe_15.fit(X_train, y_train)\n",
    "\n",
    "# selected features\n",
    "features_bool = np.array(rfe_15.support_)\n",
    "features = np.array(X_col)\n",
    "result = features[features_bool]\n",
    "print('15 selected Features:')\n",
    "print(result)        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7292\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  9  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  7  0  0  0  1  0  0  0  1  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  6  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  6  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  2  0  0  0  0  2  0  0  6  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  1  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  6  0  0  0  0  0  0  2  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  1  0  0  0  5  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  1  0  0  8  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  5  0  0  0  0  0  4]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  4  0  0  1  0  0  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  2  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  1  0  0  1  0  0  0  0  7  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  6]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfe_15.predict(X_test)\n",
    "\n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17 selected Features:\n",
      "['756' '759' '783' '789' '790' '842' '843' '854' '858' '954' '982' '983'\n",
      " '1001' '1002' '1038' '1059' '1064']\n"
     ]
    }
   ],
   "source": [
    "# RFE with 17 features\n",
    "\n",
    "rfe_17 = RFE(Rf,17)\n",
    "\n",
    "# fit with 17 features\n",
    "rfe_17.fit(X_train, y_train)\n",
    "\n",
    "# selected features\n",
    "features_bool = np.array(rfe_17.support_)\n",
    "features = np.array(X_col)\n",
    "result = features[features_bool]\n",
    "print('17 selected Features:')\n",
    "print(result)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7750\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  7  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  2  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  6  0  0  2  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  3  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  1  1  0  0  0  6  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfe_17.predict(X_test)\n",
    "\n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:761: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20 selected Features:\n",
      "['756' '759' '783' '789' '790' '799' '842' '843' '854' '858' '954' '982'\n",
      " '983' '990' '1001' '1002' '1022' '1038' '1059' '1064']\n"
     ]
    }
   ],
   "source": [
    "# RFE with 20 features\n",
    "\n",
    "rfe_20 = RFE(Rf,20)\n",
    "\n",
    "# fit with 20 features\n",
    "rfe_20.fit(X_train, y_train)\n",
    "\n",
    "# selected features\n",
    "features_bool = np.array(rfe_20.support_)\n",
    "features = np.array(X_col)\n",
    "result = features[features_bool]\n",
    "print('20 selected Features:')\n",
    "print(result)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score: 0.7250\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  6  0  0  0  0  1  0  0  1  0  0  0  0  0  0  1  0  0  0  1  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  9  0  0  0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  5  1  0  0  2  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0]\n",
      " [ 0  0  0  0  4  0  0  0  5  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  1  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  9  0  0  1  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  5  0  0  0  0  0  0  0  0  0  0  4  0]\n",
      " [ 0  0  0  0  1  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  7  0  0  0  0  0  0  3  0  0]\n",
      " [ 0  0  0  0  0  1  1  0  0  0  2  0  0  0  0  5  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  9  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  5]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  0  1  4  0  0  1  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  9  0  1  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  1  0  6  1]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  5]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = rfe_20.predict(X_test)\n",
    "\n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test, y_pred)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test, y_pred))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>756</th>\n",
       "      <th>759</th>\n",
       "      <th>783</th>\n",
       "      <th>789</th>\n",
       "      <th>790</th>\n",
       "      <th>842</th>\n",
       "      <th>843</th>\n",
       "      <th>854</th>\n",
       "      <th>858</th>\n",
       "      <th>954</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1038</th>\n",
       "      <th>1059</th>\n",
       "      <th>1064</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>-0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000033</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>0.000104</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000019</td>\n",
       "      <td>-0.000009</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>-0.000025</td>\n",
       "      <td>0.000118</td>\n",
       "      <td>0.000151</td>\n",
       "      <td>0.000012</td>\n",
       "      <td>-0.000043</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000064</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000006</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000012</td>\n",
       "      <td>-0.000011</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>-0.000027</td>\n",
       "      <td>0.000125</td>\n",
       "      <td>0.000158</td>\n",
       "      <td>0.000026</td>\n",
       "      <td>-0.000034</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>-0.000066</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000035</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>-0.000019</td>\n",
       "      <td>-0.000021</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000013</td>\n",
       "      <td>0.000111</td>\n",
       "      <td>0.000145</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>-0.000039</td>\n",
       "      <td>0.000035</td>\n",
       "      <td>-0.000062</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000016</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000007</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000105</td>\n",
       "      <td>0.000137</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>-0.000033</td>\n",
       "      <td>0.000028</td>\n",
       "      <td>-0.000063</td>\n",
       "      <td>0.000010</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        756       759       783       789       790       842       843  \\\n",
       "0  0.000019 -0.000002 -0.000017 -0.000005 -0.000007  0.000024  0.000020   \n",
       "1  0.000019 -0.000009 -0.000016 -0.000007 -0.000005  0.000024  0.000016   \n",
       "2  0.000026 -0.000006 -0.000016 -0.000012 -0.000011  0.000045  0.000041   \n",
       "3  0.000035  0.000017 -0.000005 -0.000019 -0.000021  0.000039  0.000034   \n",
       "4  0.000025 -0.000016 -0.000014 -0.000007 -0.000010  0.000036  0.000031   \n",
       "\n",
       "        854       858       954       982       983      1001      1002  \\\n",
       "0  0.000033  0.000020 -0.000019  0.000104  0.000137  0.000016 -0.000042   \n",
       "1  0.000028  0.000016 -0.000025  0.000118  0.000151  0.000012 -0.000043   \n",
       "2  0.000023  0.000023 -0.000027  0.000125  0.000158  0.000026 -0.000034   \n",
       "3  0.000022  0.000022 -0.000013  0.000111  0.000145  0.000022 -0.000039   \n",
       "4  0.000024  0.000029 -0.000008  0.000105  0.000137  0.000027 -0.000033   \n",
       "\n",
       "       1038      1059      1064  \n",
       "0  0.000024 -0.000064  0.000008  \n",
       "1  0.000029 -0.000064  0.000010  \n",
       "2  0.000030 -0.000066  0.000010  \n",
       "3  0.000035 -0.000062  0.000014  \n",
       "4  0.000028 -0.000063  0.000010  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#collecting variables selected by Rfe 17 in X_imp\n",
    "X_imp=sg_x[['756','759','783','789','790','842','843','854','858','954','982','983',\n",
    "             '1001','1002','1038','1059','1064']]\n",
    "X_col_imp=X_imp.columns\n",
    "X_imp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>756</th>\n",
       "      <th>759</th>\n",
       "      <th>783</th>\n",
       "      <th>789</th>\n",
       "      <th>790</th>\n",
       "      <th>842</th>\n",
       "      <th>843</th>\n",
       "      <th>854</th>\n",
       "      <th>858</th>\n",
       "      <th>954</th>\n",
       "      <th>982</th>\n",
       "      <th>983</th>\n",
       "      <th>1001</th>\n",
       "      <th>1002</th>\n",
       "      <th>1038</th>\n",
       "      <th>1059</th>\n",
       "      <th>1064</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1121</th>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000037</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000004</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>0.000009</td>\n",
       "      <td>-0.000014</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000032</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>0.000080</td>\n",
       "      <td>0.000061</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>-0.000102</td>\n",
       "      <td>-0.000009</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>880</th>\n",
       "      <td>-0.000042</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000031</td>\n",
       "      <td>0.000006</td>\n",
       "      <td>-0.000015</td>\n",
       "      <td>0.000005</td>\n",
       "      <td>0.000050</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.000088</td>\n",
       "      <td>0.000069</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000099</td>\n",
       "      <td>0.000004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>0.000010</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000023</td>\n",
       "      <td>0.000022</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>-0.000078</td>\n",
       "      <td>-0.000083</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>-0.000065</td>\n",
       "      <td>-0.000295</td>\n",
       "      <td>-0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1176</th>\n",
       "      <td>0.000021</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000026</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000003</td>\n",
       "      <td>-0.000005</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>-0.000068</td>\n",
       "      <td>-0.000073</td>\n",
       "      <td>0.000016</td>\n",
       "      <td>0.000034</td>\n",
       "      <td>-0.000050</td>\n",
       "      <td>-0.000306</td>\n",
       "      <td>-0.000117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0.000029</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000028</td>\n",
       "      <td>0.000018</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000020</td>\n",
       "      <td>0.000013</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>0.000024</td>\n",
       "      <td>-0.000010</td>\n",
       "      <td>0.000090</td>\n",
       "      <td>0.000127</td>\n",
       "      <td>0.000025</td>\n",
       "      <td>-0.000041</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>-0.000057</td>\n",
       "      <td>0.000014</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           756       759       783       789       790       842       843  \\\n",
       "1121 -0.000010  0.000037  0.000006 -0.000004 -0.000005  0.000006  0.000017   \n",
       "880  -0.000042  0.000005 -0.000003  0.000004  0.000004  0.000016  0.000031   \n",
       "408   0.000010 -0.000008 -0.000041  0.000023  0.000022  0.000010  0.000011   \n",
       "1176  0.000021  0.000004 -0.000026 -0.000003 -0.000003 -0.000010 -0.000003   \n",
       "283   0.000029  0.000029 -0.000028  0.000018  0.000015  0.000020  0.000013   \n",
       "\n",
       "           854       858       954       982       983      1001      1002  \\\n",
       "1121  0.000009 -0.000014 -0.000003  0.000032  0.000002  0.000080  0.000061   \n",
       "880   0.000006 -0.000015  0.000005  0.000050  0.000014  0.000088  0.000069   \n",
       "408   0.000014 -0.000002  0.000002 -0.000078 -0.000083  0.000020  0.000039   \n",
       "1176 -0.000003 -0.000005  0.000004 -0.000068 -0.000073  0.000016  0.000034   \n",
       "283   0.000042  0.000024 -0.000010  0.000090  0.000127  0.000025 -0.000041   \n",
       "\n",
       "          1038      1059      1064  \n",
       "1121  0.000003 -0.000102 -0.000009  \n",
       "880  -0.000010 -0.000099  0.000004  \n",
       "408  -0.000065 -0.000295 -0.000100  \n",
       "1176 -0.000050 -0.000306 -0.000117  \n",
       "283   0.000029 -0.000057  0.000014  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train1, X_test1, y_train1, y_test1 =train_test_split(X_imp, Y_encoded,\n",
    "                                                    test_size=0.2,\n",
    "                                                    random_state=123,stratify=Y)\n",
    "X_train1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "M:\\software\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:4: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  after removing the cwd from sys.path.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "Rf = RandomForestClassifier(random_state=52)\n",
    "Rf_fit=Rf.fit(X_train1, y_train1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = Rf.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Result:\n",
      "\n",
      "accuracy score: 0.7750\n",
      "\n",
      "Classification Report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        10\n",
      "           1       0.70      0.70      0.70        10\n",
      "           2       0.77      1.00      0.87        10\n",
      "           3       0.89      0.80      0.84        10\n",
      "           4       0.78      0.70      0.74        10\n",
      "           5       1.00      0.80      0.89        10\n",
      "           6       0.77      1.00      0.87        10\n",
      "           7       0.64      0.70      0.67        10\n",
      "           8       0.77      1.00      0.87        10\n",
      "           9       0.78      0.70      0.74        10\n",
      "          10       0.83      1.00      0.91        10\n",
      "          11       0.90      0.90      0.90        10\n",
      "          12       1.00      0.80      0.89        10\n",
      "          13       0.91      1.00      0.95        10\n",
      "          14       0.67      0.80      0.73        10\n",
      "          15       0.67      0.60      0.63        10\n",
      "          16       1.00      0.80      0.89        10\n",
      "          17       0.38      0.30      0.33        10\n",
      "          18       0.33      0.30      0.32        10\n",
      "          19       1.00      1.00      1.00        10\n",
      "          20       0.91      1.00      0.95        10\n",
      "          21       0.75      0.60      0.67        10\n",
      "          22       0.86      0.60      0.71        10\n",
      "          23       0.54      0.70      0.61        10\n",
      "\n",
      "   micro avg       0.78      0.78      0.78       240\n",
      "   macro avg       0.78      0.78      0.77       240\n",
      "weighted avg       0.78      0.78      0.77       240\n",
      "\n",
      "\n",
      "Confusion Matrix: \n",
      " [[ 8  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  7  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0  0  0  0  1  0  0  0]\n",
      " [ 0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  0]\n",
      " [ 0  0  1  0  7  0  0  0  2  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  2  0  0  8  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  7  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  1  0  0  0  0  2  0  0  7  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  9  0  0  0  0  0  0  0  0  0  0  1  0]\n",
      " [ 0  0  0  0  2  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  2  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  6  0  0  2  0  0  0  0  0]\n",
      " [ 1  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  8  0  0  0  0  0  0  0]\n",
      " [ 0  0  0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  3  0  0  0  0  0  6]\n",
      " [ 0  0  0  0  0  0  0  4  0  0  0  0  0  0  0  3  0  0  3  0  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  0  0  0  0  0  0  4  0  0  0  0  0  0  6  0  0]\n",
      " [ 0  0  0  0  0  0  0  0  1  0  0  1  0  0  0  0  0  1  1  0  0  0  6  0]\n",
      " [ 0  1  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  2  0  0  0  0  0  7]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Test Result:\\n\")        \n",
    "print(\"accuracy score: {0:.4f}\\n\".format(accuracy_score(y_test1, y_pred1)))\n",
    "print(\"Classification Report: \\n {}\\n\".format(classification_report(y_test1, y_pred1)))\n",
    "print(\"Confusion Matrix: \\n {}\\n\".format(confusion_matrix(y_test1,y_pred1))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      importance\n",
      "783     0.077909\n",
      "1064    0.073461\n",
      "1059    0.072184\n",
      "983     0.066849\n",
      "1038    0.061577\n",
      "843     0.061523\n",
      "790     0.060212\n",
      "854     0.058663\n",
      "756     0.057250\n",
      "789     0.056165\n",
      "1001    0.055357\n",
      "982     0.052648\n",
      "858     0.051490\n",
      "842     0.050144\n",
      "954     0.048654\n",
      "1002    0.048390\n",
      "759     0.047521\n"
     ]
    }
   ],
   "source": [
    "#sorting features with their importance\n",
    "feature_importances = pd.DataFrame(Rf.feature_importances_,\n",
    "                                   index = X_col_imp,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "\n",
    "print(feature_importances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features =X_col_imp\n",
    "importances = Rf.feature_importances_\n",
    "indices = np.argsort(importances)\n",
    "\n",
    "plt.title('Feature Importances')\n",
    "plt.barh(range(len(indices)), importances[indices], color='gray', align='center')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices])\n",
    "plt.xlabel('Relative Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion:- Random Forest is giving accuracy of 80% using all 331 variables. If we reduce Variables using techineque Recursive Feature Elimination(RFE),using 17 variables (756, 759, 783, 789, 790, 842, 843, 854, 858, 954, 982, 983, 1001, 1002, 1038, 1059, & 1064) model is giving acurracy of 77%. Further increase in Variables will not affecting model accuracy as much."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
